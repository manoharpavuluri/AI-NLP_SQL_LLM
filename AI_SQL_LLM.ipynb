{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_HNi-cT4JP8untLu6eKDH6rozpu7d0CZ",
      "authorship_tag": "ABX9TyPWYi4nA21szhjR4nL+LwIe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manoharpavuluri/AI_NLP_SQL_LLM/blob/main/AI_SQL_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installing Libraries**"
      ],
      "metadata": {
        "id": "1DUuPdUYpM4h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Leny36VPofcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d35de7b-ad33-493e-edb8-24b8e557afa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m856.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.0/336.0 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.0/607.0 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.2/407.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.6/88.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for python-tds (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.27.0, but you have google-auth 2.35.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai langchain_community langchain pyodbc pymysql chromadb python-dotenv -q\n",
        "!pip install --upgrade --quiet langchain-google-cloud-sql-mssql langchain-google-vertexai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Then read the .env file securely from your Google Drive\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv('/content/drive/MyDrive/Colab Notebooks/AI_SQL_LLM/config.env')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOt0fLpUpKsT",
        "outputId": "9156a774-d6fe-4b24-ea23-4301be061289"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Access the credentials\n",
        "mysql_db_user = os.getenv(\"MYSQL_DB_USER\")\n",
        "mysql_db_pass = os.getenv(\"MYSQL_DB_PASS\")\n",
        "mysql_db_host = os.getenv(\"MYSQL_DB_HOST\")\n",
        "mysql_db_name = os.getenv(\"MYSQL_DB_NAME\")"
      ],
      "metadata": {
        "id": "qSZlSxviXYuL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making SQL Connection using Langchain**\n",
        "\n"
      ],
      "metadata": {
        "id": "95psiW8Uh58J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities.sql_database import SQLDatabase\n",
        "\n",
        "mysql_db = SQLDatabase.from_uri(f\"mysql+pymysql://{mysql_db_user}:{mysql_db_pass}@{mysql_db_host}/{mysql_db_name}\")\n"
      ],
      "metadata": {
        "id": "tLyeg9Sxpf7H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mysql_db.dialect)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9tT3dAHWWPB",
        "outputId": "9c4b45ae-69a9-44bc-8304-24f1d184c23e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mysql\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mysql_db.get_usable_table_names())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF2yEFBUa4Kg",
        "outputId": "bad6c737-d937-4a58-8c26-5cf105c7aed9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['customers', 'employees', 'offices', 'orderdetails', 'orders', 'payments', 'productlines', 'products']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(mysql_db.table_info)"
      ],
      "metadata": {
        "id": "BgienG7WbM5k"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAPI')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN')\n"
      ],
      "metadata": {
        "id": "1RB-5Z99jK9T"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_sql_query_chain\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "73AIQlt6NdvD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adding OpenAI Chat mode**\n",
        "**to turn sentence into query**"
      ],
      "metadata": {
        "id": "mrUnGAG8jM06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using the model from ChatOpenAI, and mysql_db from langchain_community,\n",
        "# you are converting the 'question' to sql query\n",
        "\n",
        "llm = ChatOpenAI(model = \"gpt-3.5-turbo\", temperature =0)\n",
        "generate_query = create_sql_query_chain(llm,mysql_db)\n",
        "query = generate_query.invoke({\"question\": \"what is price of '1968 Ford Mustang'\"})\n",
        "print(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxgmCu6mOBjv",
        "outputId": "8727a766-cfa3-4149-bc9c-2e7d0bc03a4a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT `buyPrice`, `MSRP` \n",
            "FROM products \n",
            "WHERE `productName` = '1968 Ford Mustang'\n",
            "LIMIT 1;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
        "execute_query = QuerySQLDataBaseTool(db= mysql_db)\n",
        "execute_query.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PCPrPo97PNrY",
        "outputId": "12da62da-1b31-4757-e6d4-8b0fa3c96456"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[(Decimal('95.34'), Decimal('194.57'))]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = generate_query | execute_query\n",
        "chain.invoke({\"question\": \"How many orders are there?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "quKtGqKyXlq3",
        "outputId": "1ec97d98-32cc-4378-8a3c-e38b74eea7cf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[(326,)]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.get_prompts()[0].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlP0EG4NdLZC",
        "outputId": "00719f47-3dc2-4d0f-ac59-6460754373cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a MySQL expert. Given an input question, first create a syntactically correct MySQL query to run, then look at the results of the query and return the answer to the input question.\n",
            "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per MySQL. You can order the results to return the most informative data in the database.\n",
            "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
            "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
            "Pay attention to use CURDATE() function to get the current date, if the question involves \"today\".\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: Question here\n",
            "SQLQuery: SQL Query to run\n",
            "SQLResult: Result of the SQLQuery\n",
            "Answer: Final answer here\n",
            "\n",
            "Only use the following tables:\n",
            "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
            "\n",
            "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adding prompt template**"
      ],
      "metadata": {
        "id": "bzRUNPQdjx5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "answer_prompt = PromptTemplate.from_template(\n",
        "  \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
        "\n",
        "  Question: {question}\n",
        "  SQL Query: {query}\n",
        "  SQL Result: {result}\n",
        "  Answer: \"\"\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "ghv3Ps_LdZSz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rephrase_answer = answer_prompt | llm | StrOutputParser()\n",
        "\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(query = generate_query).assign(\n",
        "        result = itemgetter(\"query\") | execute_query\n",
        "    )\n",
        "    | rephrase_answer\n",
        ")\n",
        "\n",
        "chain.invoke({\"question\": \"How many customers have an order count greater than 5\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eslhL4AFfZm5",
        "outputId": "11e534d8-294f-4402-ad45-c6f5e4d1cec2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are 2 customers who have an order count greater than 5.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Enhancing NL2SQL Models with Few-Shot Examples**"
      ],
      "metadata": {
        "id": "VPyhz685EJ1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " examples = [\n",
        "     {\n",
        "         \"input\": \"List all customers in France with a credit limit over 20,000.\",\n",
        "         \"query\": \"SELECT * FROM customers WHERE country = 'France' AND creditLimit > 20000;\"\n",
        "     },\n",
        "     {\n",
        "         \"input\": \"Get the highest payment amount made by any customer.\",\n",
        "         \"query\": \"SELECT MAX(amount) FROM payments;\"\n",
        "     }\n",
        " ]\n"
      ],
      "metadata": {
        "id": "tapCW1CVgoJg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, FewShotChatMessagePromptTemplate, PromptTemplate\n",
        "\n",
        "example_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\\nSQLQuery:\"),\n",
        "        (\"ai\", \"{query}\"),\n",
        "    ]\n",
        ")\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt = example_prompt,\n",
        "    examples = examples,\n",
        "    # input_variables = [\"input\", \"top_k\"],\n",
        "    input_variables = [\"input\"],\n",
        ")\n",
        "print(few_shot_prompt.format(input1 = \"how many products are there?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NOpIWOxEcDt",
        "outputId": "d840e298-9334-4d06-b1f7-ac3bb28f6b31"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: List all customers in France with a credit limit over 20,000.\n",
            "SQLQuery:\n",
            "AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit > 20000;\n",
            "Human: Get the highest payment amount made by any customer.\n",
            "SQLQuery:\n",
            "AI: SELECT MAX(amount) FROM payments;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from langchain_community.vectorstores import Chroma\n",
        " from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
        " from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        " vectorstore = Chroma()\n",
        " vectorstore.delete_collection()\n",
        " example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
        "     examples,\n",
        "     OpenAIEmbeddings(),\n",
        "     vectorstore,\n",
        "     k=2,\n",
        "     input_keys=[\"input\"],\n",
        " )\n",
        " example_selector.select_examples({\"input\": \"how many employees we have?\"})\n",
        " few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "     example_prompt=example_prompt,\n",
        "     example_selector=example_selector,\n",
        "     input_variables=[\"input\",\"top_k\"],\n",
        " )\n",
        " print(few_shot_prompt.format(input=\"How many products are there?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBrDnCsEGDbU",
        "outputId": "26e541d7-dce4-4816-9bf1-01a782679cd0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: List all customers in France with a credit limit over 20,000.\n",
            "SQLQuery:\n",
            "AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit > 20000;\n",
            "Human: Get the highest payment amount made by any customer.\n",
            "SQLQuery:\n",
            "AI: SELECT MAX(amount) FROM payments;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " final_prompt = ChatPromptTemplate.from_messages(\n",
        "     [\n",
        "         (\"system\", \"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\n\\nHere is the relevant table info: {table_info}\\n\\nBelow are a number of examples of questions and their corresponding SQL queries.\"),\n",
        "         few_shot_prompt,\n",
        "         (\"human\", \"{input}\"),\n",
        "     ]\n",
        " )\n",
        " print(final_prompt.format(input=\"How many products are there?\",table_info=\"some table info\"))\n",
        " generate_query = create_sql_query_chain(llm, mysql_db,final_prompt)\n",
        " chain = (\n",
        " RunnablePassthrough.assign(query=generate_query).assign(\n",
        "     result=itemgetter(\"query\") | execute_query\n",
        " )\n",
        " | rephrase_answer\n",
        " )\n",
        " chain.invoke({\"question\": \"How many csutomers with credit limit more than 50000\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "t2j3Mu4VQn3h",
        "outputId": "72ca13c0-2960-4d79-8d14-b46293a33094"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System: You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\n",
            "\n",
            "Here is the relevant table info: some table info\n",
            "\n",
            "Below are a number of examples of questions and their corresponding SQL queries.\n",
            "Human: List all customers in France with a credit limit over 20,000.\n",
            "SQLQuery:\n",
            "AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit > 20000;\n",
            "Human: Get the highest payment amount made by any customer.\n",
            "SQLQuery:\n",
            "AI: SELECT MAX(amount) FROM payments;\n",
            "Human: How many products are there?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are 85 customers with a credit limit greater than 50000.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from langchain.chains.openai_tools import create_extraction_chain_pydantic\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import List\n",
        "import pandas as pd\n",
        "\n",
        "def get_table_details():\n",
        "    # Read the CSV file into a DataFrame\n",
        "    table_description = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AI_SQL_LLM/database_table_descriptions.csv\")\n",
        "    table_docs = []\n",
        "\n",
        "    # Iterate over the DataFrame rows to create Document objects\n",
        "    table_details = \"\"\n",
        "    for index, row in table_description.iterrows():\n",
        "        table_details = table_details + \"Table Name:\" + row['Table'] + \"\\n\" + \"Table Description:\" + row['Description'] + \"\\n\\n\"\n",
        "\n",
        "    return table_details\n",
        "\n",
        "\n",
        "class Table(BaseModel):\n",
        "    \"\"\"Table in SQL database.\"\"\"\n",
        "\n",
        "    name: str = Field(description=\"Name of table in SQL database.\")\n",
        "\n",
        "# table_names = \"\\n\".join(db.get_usable_table_names())\n",
        "table_details = get_table_details()\n",
        "print(table_details)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osr3xaneV48D",
        "outputId": "e3c73890-efb5-4436-aaec-4da605aecd90"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table Name:employees\n",
            "Table Description:employees\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table_details_prompt = f\"\"\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\n",
        "The tables are:\n",
        "\n",
        "{table_details}\n",
        "\n",
        "Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\"\"\"\n",
        "\n",
        "table_chain = create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt)\n",
        "tables = table_chain.invoke({\"input\": \"give me details of customer and their order count\"})\n",
        "tables\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X043WUwXV5kV",
        "outputId": "c4dd3b30-acde-4bba-dc26-d4165ff1b4e7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-3d47447c16a4>:8: LangChainDeprecationWarning: LangChain has introduced a method called `with_structured_output` thatis available on ChatModels capable of tool calling.You can read more about the method here: <https://python.langchain.com/docs/modules/model_io/chat/structured_output/>. Please follow our extraction use case documentation for more guidelineson how to do information extraction with LLMs.<https://python.langchain.com/docs/use_cases/extraction/>. with_structured_output does not currently support a list of pydantic schemas. If this is a blocker or if you notice other issues, please provide feedback here:<https://github.com/langchain-ai/langchain/discussions/18154>\n",
            "  table_chain = create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Table(name='customers'), Table(name='orders')]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tables(tables: List[Table]) -> List[str]:\n",
        "    tables  = [table.name for table in tables]\n",
        "    return tables\n",
        "\n",
        "select_table = {\"input\": itemgetter(\"question\")} | create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt) | get_tables\n",
        "select_table.invoke({\"question\": \"give me details of customer and their order count\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBYH87VfYk35",
        "outputId": "42360ca8-36ca-4e23-ab80-620d1be0cfca"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['customers', 'orders']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "RunnablePassthrough.assign(table_names_to_use=select_table) |\n",
        "RunnablePassthrough.assign(query=generate_query).assign(\n",
        "    result=itemgetter(\"query\") | execute_query\n",
        ")\n",
        "| rephrase_answer\n",
        ")\n",
        "chain.invoke({\"question\": \"How many cutomers with order count more than 5\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VGoGQiOcYqON",
        "outputId": "fd6c475a-e1f0-41f1-8aa3-e8604e98215a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are 2 customers with an order count of more than 5.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from langchain.memory import ChatMessageHistory\n",
        " history = ChatMessageHistory()\n"
      ],
      "metadata": {
        "id": "ILSVQ4lJYn8v"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " final_prompt = ChatPromptTemplate.from_messages(\n",
        "     [\n",
        "         (\"system\", \"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\n\\nHere is the relevant table info: {table_info}\\n\\nBelow are a number of examples of questions and their corresponding SQL queries. Those examples are just for referecne and hsould be considered while answering follow up questions\"),\n",
        "         few_shot_prompt,\n",
        "         MessagesPlaceholder(variable_name=\"messages\"),\n",
        "         (\"human\", \"{input}\"),\n",
        "     ]\n",
        " )\n",
        " print(final_prompt.format(input=\"How many products are there?\",table_info=\"some table info\",messages=[]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP3FSGx8Ytug",
        "outputId": "eb1e0c0e-e33d-4f56-ef09-c2871006b06e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System: You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\n",
            "\n",
            "Here is the relevant table info: some table info\n",
            "\n",
            "Below are a number of examples of questions and their corresponding SQL queries. Those examples are just for referecne and hsould be considered while answering follow up questions\n",
            "Human: List all customers in France with a credit limit over 20,000.\n",
            "SQLQuery:\n",
            "AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit > 20000;\n",
            "Human: Get the highest payment amount made by any customer.\n",
            "SQLQuery:\n",
            "AI: SELECT MAX(amount) FROM payments;\n",
            "Human: How many products are there?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " generate_query = create_sql_query_chain(llm, mysql_db,final_prompt)\n",
        "\n",
        " chain = (\n",
        " RunnablePassthrough.assign(table_names_to_use=select_table) |\n",
        " RunnablePassthrough.assign(query=generate_query).assign(\n",
        "     result=itemgetter(\"query\") | execute_query\n",
        " )\n",
        " | rephrase_answer\n",
        " )\n"
      ],
      "metadata": {
        "id": "6W706pvXYzTm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How many cutomers with order count more than 5\"\n",
        "response = chain.invoke({\"question\": question,\"messages\":history.messages})\n"
      ],
      "metadata": {
        "id": "YNUFx0hwY2Bi"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.add_user_message(question)\n",
        "history.add_ai_message(response)\n",
        "history.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyZfGRU-Y8CC",
        "outputId": "714cc61e-6c3a-433b-c046-382a528820ca"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='How many cutomers with order count more than 5', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='There are 2 customers with an order count of more than 5.', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke({\"question\": \"Can you list there names?\",\"messages\":history.messages})\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oqCTmwRigZfP",
        "outputId": "f9dfc2d3-6c5c-4e6a-9d5e-dcb377a5789b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The names of the customers who have placed more than 5 orders are 'Mini Gifts Distributors Ltd.' and 'Euro+ Shopping Channel'.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9tqXnPKQgexb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}